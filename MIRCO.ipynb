{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum Rule Cover - MIRCO\n",
    "\n",
    "Minimum Cover Boosting (MIRCO) algorithm aims at extracting a small set of rules that could be used to interpret a model trained with Random Forest (RF) algorithm. In this note, we demonstrate how one can use MIRCO and assess it success in mimicking the underlying random forest model.\n",
    "\n",
    "We start with adding the required packages. Please note that except MIRCO (provided here) all other packages are bundled with the standard installation of [Anaconda Distribution](https://www.anaconda.com/products/individual) (Pyhton 3.7). Our implementation also imports the `gurobipy` Python package that can be separately installed by the Anaconda package manager. Note that along with the Python package, you also need to install [Gurobi Optimizer](https://www.gurobi.com/academia/academic-program-and-licenses/), which is free for research and educational work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from MIRCO import MIRCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of problems that we can try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RuleCoverDatasets as RCDS\n",
    "problems = [RCDS.banknote, RCDS.ILPD, RCDS.ionosphere,\n",
    "            RCDS.transfusion, RCDS.liver, RCDS.tictactoe,\n",
    "            RCDS.wdbc, RCDS.mammography, RCDS.diabetes, \n",
    "            RCDS.oilspill, RCDS.phoneme, RCDS.seeds, RCDS.wine,\n",
    "            RCDS.glass, RCDS.ecoli]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example let's work with problem `ionosphere` and import its dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.array(RCDS.ionosphere('datasets/'))                                                                       \n",
    "X = df[:, 0:-1]                                                                    \n",
    "y = df[:, -1]                                                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will use the *entire* data set for training a random forest classifier. Then, we will obtain the predictions with both the random forest model and the set of rules extracted by MIRCO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomstate = 13 # Random seed is fixed\n",
    "crit = \"gini\" # Impurity criterion (for now only other option is \"entropy\")\n",
    "\n",
    "# Random Forest\n",
    "RF = RandomForestClassifier(random_state=randomstate, criterion=crit)\n",
    "RF_fit = RF.fit(X, y)\n",
    "RF_pred = RF_fit.predict(X)\n",
    "\n",
    "# MIRCO\n",
    "MRC = MIRCO(RF_fit)\n",
    "MRC_fit = MRC.fit(X, y)\n",
    "MRC_pred = MRC_fit.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using the entire dataset, we naturally obtain quite optimistic accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ACCURACIES ##\n",
      "Random Forest:  1.0\n",
      "MIRCO:  0.9515669515669516\n"
     ]
    }
   ],
   "source": [
    "print('## ACCURACIES ##')\n",
    "print('Random Forest: ', accuracy_score(RF_pred, y)) \n",
    "print('MIRCO: ', accuracy_score(MRC_pred, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the numbers of rules generated by the random forest algorithm ant MIRCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## NUMBERS OF RULES ##\n",
      "Random Forest:  2433\n",
      "MIRCO:  11\n"
     ]
    }
   ],
   "source": [
    "print('\\n## NUMBERS OF RULES ##')\n",
    "print('Random Forest: ', MRC_fit.initNumOfRules)\n",
    "print('MIRCO: ', MRC_fit.numOfRules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These figures show that MIRCO obtains a close-enough performance with a significantly less number of rules. As we use the entire data set, MIRCO covers *all* the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missed test samples by MIRCO:  0\n"
     ]
    }
   ],
   "source": [
    "print('Number of missed test samples by MIRCO: ', MRC_fit.numOfMissed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For interpretation, we can also print the set of rules used by MIRCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Rules obtained by MIRCO\n",
      "RULE 0:\n",
      "==> x[0] > 0.50\n",
      "==> x[30] > 0.19\n",
      "==> x[22] > -0.81\n",
      "==> x[7] > -0.99\n",
      "==> x[23] <= 0.45\n",
      "==> x[17] > -0.81\n",
      "==> x[2] > 0.13\n",
      "==> x[31] <= 0.64\n",
      "==> x[32] > -0.12\n",
      "==> x[30] > 0.49\n",
      "==> Class numbers: [1.00, 123.00]\n",
      "RULE 1:\n",
      "==> x[13] <= -0.56\n",
      "==> Class numbers: [32.00, 1.00]\n",
      "RULE 2:\n",
      "==> x[2] > 0.19\n",
      "==> x[26] <= 1.00\n",
      "==> x[22] <= 0.09\n",
      "==> x[4] > 0.08\n",
      "==> x[7] > -0.58\n",
      "==> x[4] > 0.42\n",
      "==> Class numbers: [1.00, 50.00]\n",
      "RULE 3:\n",
      "==> x[28] > 0.13\n",
      "==> x[33] > 0.95\n",
      "==> x[7] > 0.61\n",
      "==> Class numbers: [10.00, 1.00]\n",
      "RULE 4:\n",
      "==> x[6] > 0.04\n",
      "==> x[23] > -0.99\n",
      "==> x[7] > -0.99\n",
      "==> x[7] <= 0.99\n",
      "==> x[4] > 0.03\n",
      "==> x[27] > -0.96\n",
      "==> x[3] > -0.74\n",
      "==> x[7] > -0.63\n",
      "==> x[5] <= 0.80\n",
      "==> x[11] > -0.12\n",
      "==> Class numbers: [8.00, 183.00]\n",
      "RULE 5:\n",
      "==> x[4] <= 0.04\n",
      "==> Class numbers: [67.00, 0.00]\n",
      "RULE 6:\n",
      "==> x[19] > -0.94\n",
      "==> x[4] > 0.23\n",
      "==> x[2] > 0.11\n",
      "==> x[3] > -0.80\n",
      "==> x[21] <= 0.91\n",
      "==> x[32] <= 0.99\n",
      "==> x[23] <= 0.16\n",
      "==> Class numbers: [5.00, 154.00]\n",
      "RULE 7:\n",
      "==> x[4] > 0.04\n",
      "==> x[7] > -0.90\n",
      "==> x[6] > 0.01\n",
      "==> x[13] > -0.66\n",
      "==> x[33] <= 0.95\n",
      "==> x[5] > -0.14\n",
      "==> x[17] <= -0.77\n",
      "==> Class numbers: [3.00, 0.00]\n",
      "RULE 8:\n",
      "==> x[0] <= 0.50\n",
      "==> Class numbers: [38.00, 0.00]\n",
      "RULE 9:\n",
      "==> x[7] <= -0.63\n",
      "==> x[21] > -0.13\n",
      "==> Class numbers: [25.00, 1.00]\n",
      "RULE 10:\n",
      "==> x[2] <= 0.20\n",
      "==> Class numbers: [60.00, 1.00]\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\nRules obtained by MIRCO')\n",
    "MRC_fit.exportRules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though MIRCO itself is not a classifier, we can also apply the rules that it extracts from a random forest model. Suppose we apply a standard train-test split to the dataset and compare the results of MIRCO against a decision tree classifier and a random forest classifier (the one used for rule extraction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ACCURACIES ##\n",
      "Decision Tree:  0.8867924528301887\n",
      "Random Forest:  0.9433962264150944\n",
      "MIRCO:  0.9150943396226415\n",
      "\n",
      "## NUMBERS OF RULES ##\n",
      "Decision Tree:  23\n",
      "Random Forest:  2062\n",
      "MIRCO:  10\n"
     ]
    }
   ],
   "source": [
    "randomstate = 67 # Random seed is fixed\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=randomstate)                                           \n",
    "\n",
    "# Decision Tree\n",
    "DT = DecisionTreeClassifier(random_state=randomstate, criterion=crit)\n",
    "DT_fit = DT.fit(X_train, y_train)\n",
    "DT_pred = DT_fit.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "RF = RandomForestClassifier(random_state=randomstate, criterion=crit)\n",
    "RF_fit = RF.fit(X_train, y_train)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "\n",
    "# MIRCO\n",
    "MRC = MIRCO(RF_fit)\n",
    "MRC_fit = MRC.fit(X_train, y_train)\n",
    "MRC_pred = MRC_fit.predict(X_test)\n",
    "\n",
    "print('## ACCURACIES ##')\n",
    "print('Decision Tree: ', accuracy_score(DT_pred, y_test)) \n",
    "print('Random Forest: ', accuracy_score(RF_pred, y_test)) \n",
    "print('MIRCO: ', accuracy_score(MRC_pred, y_test))\n",
    "print('\\n## NUMBERS OF RULES ##')\n",
    "print('Decision Tree: ', DT_fit.tree_.n_leaves)\n",
    "print('Random Forest: ', MRC_fit.initNumOfRules)\n",
    "print('MIRCO: ', MRC_fit.numOfRules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIRCO outperforms the decision tree classifier with a half of the number of rules generated by the decision tree algorithm. However, as we have applied a train-test split, some of the test samples may not be covered with MIRCO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missed test samples by MIRCO:  6\n"
     ]
    }
   ],
   "source": [
    "print('Number of missed test samples by MIRCO: ', MRC_fit.numOfMissed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the accuracy values reported above do include the missed points because we still classify such samples by applying the rules that have the largest fraction of accepted clauses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
